# Evidence: T04.4.3_JD-AGENT002_PromptContract

## Prompt Contract
- Output shape: JSON object with a single required field: `{ "reply": string }`.
- The backend requests JSON formatting from Ollama via `format: "json"`.
- The backend attempts to parse JSON; on parse failure it falls back to treating the model response as plain text.

## Where Implemented
- Prompt + message construction: [src/main.py](Reserved/DocExtractor/src/main.py)
- JSON parsing helper: [src/llm/ollama_http.py](Reserved/DocExtractor/src/llm/ollama_http.py)

## Smoke Evidence
- `scripts/ollama_smoke_test.py` produced a valid JSON reply from `llama3.1:8b`.
