# Data Dictionary: Column Definitions & Constraints

**Task:** T02.3.1_JD-DEV003_DesignSQLSchema  
**Evidence Artifact:** Data Dictionary  
**Created By:** DEV-003 (Database Developer)  
**Date:** 2026-01-14

---

## Executive Summary

Complete data dictionary for 7-table schema. Every column documented with type, constraints, acceptable ranges, and purpose. Ensures consistent understanding between schema design and implementation.

---

## 1. import_batches Table

| Column | Type | Constraints | Range | Purpose |
|--------|------|-------------|-------|---------|
| id | UUID | PRIMARY KEY, DEFAULT gen_random_uuid() | N/A | Unique batch identifier |
| batch_time | TIMESTAMPTZ | NOT NULL, DEFAULT NOW() | Any valid timestamp | When batch import started |
| import_source | VARCHAR(255) | NOT NULL | 1-255 chars | File path or system name (e.g., "/home/user/docs", "s3://bucket") |
| import_user | VARCHAR(255) | NULL | 1-255 chars | User ID who initiated batch (for audit) |
| doc_count | INTEGER | NOT NULL, CHECK (>= 0) | 0-2B | Number of documents in batch |
| status | VARCHAR(50) | NOT NULL, DEFAULT 'pending' | 'pending', 'complete', 'failed' | Batch state |
| created_at | TIMESTAMPTZ | NOT NULL, DEFAULT NOW() | N/A | Record creation timestamp (immutable) |

**Example Row:**
```
id: 550e8400-e29b-41d4-a716-446655440000
batch_time: 2026-01-14 08:30:00+00
import_source: /home/admin/batch_001
import_user: admin@company.com
doc_count: 847
status: complete
```

---

## 2. documents Table

| Column | Type | Constraints | Range | Purpose |
|--------|------|-------------|-------|---------|
| id | UUID | PRIMARY KEY, DEFAULT gen_random_uuid() | N/A | Unique document identifier |
| filename | VARCHAR(512) | NOT NULL | 1-512 chars | Document filename (e.g., "invoice_2024.pdf") |
| file_size_bytes | BIGINT | NOT NULL, CHECK (> 0) | 1-9B | File size in bytes (range: ~1byte to 1GB practical) |
| file_format | VARCHAR(50) | NOT NULL | 'pdf', 'docx', 'jpg', 'png', 'txt', etc. | File type |
| sha256_hash | VARCHAR(64) | NOT NULL, UNIQUE | 64-char hex string | SHA-256 hash (UNIQUE enforces zero duplicates) |
| import_batch_id | UUID | NOT NULL, FK → import_batches(id) | Valid UUID | Reference to import batch |
| import_time | TIMESTAMPTZ | NOT NULL | Any valid timestamp | When document was imported |
| import_source_path | TEXT | NULL | 1-64KB | Full path of document in source (for reprocessing) |
| status | VARCHAR(50) | NOT NULL, DEFAULT 'new' | 'new', 'duplicate', 'classified', 'tagged', 'archived' | Document state |
| created_at | TIMESTAMPTZ | NOT NULL, DEFAULT NOW() | N/A | Record creation timestamp (immutable) |
| updated_at | TIMESTAMPTZ | NOT NULL, DEFAULT NOW() | N/A | Last update timestamp (updated on status change) |

**Example Row:**
```
id: 660e8400-e29b-41d4-a716-446655440001
filename: invoice_2024_Q1.pdf
file_size_bytes: 245600
file_format: pdf
sha256_hash: a3d8f4c2e8b1f5d9e6c4a2f8b3e1d5c9a7f2b4e6d8c1a3f5b7e9d2c4a6f8b1
import_batch_id: 550e8400-e29b-41d4-a716-446655440000
import_time: 2026-01-14 08:35:22+00
status: classified
```

---

## 3. document_hashes Table

| Column | Type | Constraints | Range | Purpose |
|--------|------|-------------|-------|---------|
| id | BIGSERIAL | PRIMARY KEY | 1-9B | Auto-incrementing row ID |
| doc_id | UUID | NOT NULL, UNIQUE, FK → documents(id) | Valid UUID | Reference to document (one-to-one) |
| hash | VARCHAR(64) | NOT NULL, UNIQUE INDEX | 64-char hex string | SHA-256 hash (indexed for < 10ms lookups) |
| is_duplicate | BOOLEAN | NOT NULL, DEFAULT FALSE | TRUE/FALSE | TRUE if document is a duplicate |
| first_seen | TIMESTAMPTZ | NOT NULL, DEFAULT NOW() | Any valid timestamp | When this hash was first seen (immutable) |
| duplicate_of_doc_id | UUID | NULL, FK → documents(id) | Valid UUID or NULL | Reference to original document if is_duplicate=TRUE |
| created_at | TIMESTAMPTZ | NOT NULL, DEFAULT NOW() | N/A | Record creation timestamp (immutable) |

**Example Rows:**

*Original document:*
```
id: 1
doc_id: 660e8400-e29b-41d4-a716-446655440001
hash: a3d8f4c2e8b1f5d9e6c4a2f8b3e1d5c9a7f2b4e6d8c1a3f5b7e9d2c4a6f8b1
is_duplicate: FALSE
first_seen: 2026-01-14 08:35:22+00
duplicate_of_doc_id: NULL
```

*Duplicate detected later:*
```
id: 2
doc_id: 660e8400-e29b-41d4-a716-446655440002
hash: a3d8f4c2e8b1f5d9e6c4a2f8b3e1d5c9a7f2b4e6d8c1a3f5b7e9d2c4a6f8b1
is_duplicate: TRUE
first_seen: 2026-01-14 09:15:00+00
duplicate_of_doc_id: 660e8400-e29b-41d4-a716-446655440001
```

**Performance Note:** UNIQUE INDEX on hash enables < 10ms lookups for deduplication checks.

---

## 4. document_classifications Table

| Column | Type | Constraints | Range | Purpose |
|--------|------|-------------|-------|---------|
| id | BIGSERIAL | PRIMARY KEY | 1-9B | Auto-incrementing row ID |
| doc_id | UUID | NOT NULL, FK → documents(id) | Valid UUID | Reference to document |
| category | VARCHAR(100) | NOT NULL | 1-100 chars | Classification category (e.g., "invoice", "receipt", "contract") |
| confidence | DECIMAL(3,2) | NOT NULL, CHECK ([0,1]) | 0.00-1.00 | Confidence score (0 = 0%, 1 = 100%) |
| model_version | VARCHAR(50) | NULL | 1-50 chars | Model version used for classification (e.g., "v1.0", "gpt-4-turbo") |
| classified_at | TIMESTAMPTZ | NOT NULL, DEFAULT NOW() | Any valid timestamp | When classification was generated |
| created_at | TIMESTAMPTZ | NOT NULL, DEFAULT NOW() | N/A | Record creation timestamp |
| (UNIQUE) | (doc_id, category, model_version) | Composite unique constraint | N/A | Prevent duplicate classifications per model |

**Example Row:**
```
id: 5
doc_id: 660e8400-e29b-41d4-a716-446655440001
category: invoice
confidence: 0.94
model_version: v1.0
classified_at: 2026-01-14 08:36:10+00
```

**Acceptable Confidence Range:**
- 0.00-0.50: Low confidence (< 50%) – consider manual review
- 0.50-0.80: Medium confidence (50-80%) – typical threshold
- 0.80-1.00: High confidence (> 80%) – can auto-process

---

## 5. tags Table

| Column | Type | Constraints | Range | Purpose |
|--------|------|-------------|-------|---------|
| id | BIGSERIAL | PRIMARY KEY | 1-9B | Auto-incrementing tag ID |
| tag_name | VARCHAR(100) | NOT NULL, UNIQUE | 1-100 chars | Tag name (e.g., "confidential", "archived", "reviewed") |
| description | TEXT | NULL | 1-64KB | Human-readable tag description |
| created_by | VARCHAR(255) | NULL | 1-255 chars | User who created tag (for audit) |
| created_at | TIMESTAMPTZ | NOT NULL, DEFAULT NOW() | N/A | Record creation timestamp |

**Example Rows:**
```
id: 1
tag_name: confidential
description: Documents marked as confidential by company policy
created_by: admin@company.com
created_at: 2026-01-01 00:00:00+00

id: 2
tag_name: reviewed
description: Documents reviewed and approved by legal
created_by: legal@company.com
created_at: 2026-01-05 14:30:00+00
```

---

## 6. document_tags Table (Bridge)

| Column | Type | Constraints | Range | Purpose |
|--------|------|-------------|-------|---------|
| id | BIGSERIAL | PRIMARY KEY | 1-9B | Auto-incrementing row ID |
| doc_id | UUID | NOT NULL, FK → documents(id), ON DELETE CASCADE | Valid UUID | Reference to document |
| tag_id | BIGINT | NOT NULL, FK → tags(id) | Valid BIGINT | Reference to tag |
| assigned_at | TIMESTAMPTZ | NOT NULL, DEFAULT NOW() | Any valid timestamp | When tag was assigned |
| assigned_by | VARCHAR(255) | NULL | 1-255 chars | User who assigned tag |
| created_at | TIMESTAMPTZ | NOT NULL, DEFAULT NOW() | N/A | Record creation timestamp |
| (UNIQUE) | (doc_id, tag_id) | Composite unique constraint | N/A | Prevent duplicate tag assignments |

**Example Rows:**
```
id: 1
doc_id: 660e8400-e29b-41d4-a716-446655440001
tag_id: 1
assigned_at: 2026-01-14 10:00:00+00
assigned_by: user@company.com

id: 2
doc_id: 660e8400-e29b-41d4-a716-446655440001
tag_id: 2
assigned_at: 2026-01-14 10:05:00+00
assigned_by: legal@company.com
```

**ON DELETE CASCADE:** If document deleted, all tags for that document are automatically removed.

---

## 7. audit_log Table (IMMUTABLE)

| Column | Type | Constraints | Range | Purpose |
|--------|------|-------------|-------|---------|
| id | BIGSERIAL | PRIMARY KEY | 1-9B | Auto-incrementing audit record ID |
| entity_type | VARCHAR(50) | NOT NULL | 'document', 'hash', 'classification', 'tag' | What entity was audited |
| entity_id | VARCHAR(255) | NOT NULL | 1-255 chars | ID of audited entity (UUID or similar) |
| action | VARCHAR(50) | NOT NULL | 'import', 'duplicate_detected', 'classified', 'tagged', 'archived' | What action occurred |
| timestamp | TIMESTAMPTZ | NOT NULL | Any valid timestamp | When action occurred (business time, not creation time) |
| user_id | VARCHAR(255) | NULL | 1-255 chars | User responsible for action |
| old_value | JSONB | NULL | Any JSON | State before action (for updates) |
| new_value | JSONB | NULL | Any JSON | State after action |
| reason | TEXT | NULL | 1-64KB | Explanation for action (e.g., "duplicate hash detected", "classified as invoice") |
| created_at | TIMESTAMPTZ | NOT NULL, DEFAULT NOW() | N/A | Record creation timestamp (immutable) |

**Example Rows:**

*Document import:*
```
id: 1
entity_type: document
entity_id: 660e8400-e29b-41d4-a716-446655440001
action: import
timestamp: 2026-01-14 08:35:22+00
user_id: admin@company.com
old_value: NULL
new_value: {"filename": "invoice_2024.pdf", "size": 245600}
reason: Document imported from batch 550e8400-e29b-41d4-a716-446655440000
```

*Duplicate detected:*
```
id: 2
entity_type: hash
entity_id: a3d8f4c2e8b1f5d9e6c4a2f8b3e1d5c9a7f2b4e6d8c1a3f5b7e9d2c4a6f8b1
action: duplicate_detected
timestamp: 2026-01-14 09:15:00+00
user_id: system
old_value: NULL
new_value: {"is_duplicate": true, "duplicate_of": "660e8400-e29b-41d4-a716-446655440001"}
reason: Hash matched existing document in document_hashes
```

*Classification:*
```
id: 3
entity_type: document
entity_id: 660e8400-e29b-41d4-a716-446655440001
action: classified
timestamp: 2026-01-14 08:36:10+00
user_id: classifier@company.com
old_value: {"status": "new"}
new_value: {"status": "classified"}
reason: LLM classifier (v1.0) assigned category "invoice" with 0.94 confidence
```

---

## Key Constraints & Validations

### Data Type Rationale

| Data Type | Used For | Rationale |
|-----------|----------|-----------|
| UUID | IDs (documents, batches) | Distributed generation, no sequential guessing |
| BIGSERIAL | Auto-increment (audit_log, tags) | Large sequential values; safe for 100M+ rows |
| VARCHAR(N) | Strings with max length | Enforce max length; document filenames, user IDs |
| TEXT | Unlimited strings | Audit reasons, descriptions; no size constraint |
| JSONB | Flexible schema | Audit trail flexibility; old/new values can vary |
| DECIMAL(3,2) | Confidence scores | Precise decimal arithmetic (0.00-1.00) |
| TIMESTAMPTZ | Timestamps | Timezone-aware; important for multi-region systems |
| BIGINT | File sizes, counts | Support up to ~9 billion bytes (9GB files) |

### Constraint Hierarchy

1. **Primary Keys** – Enforce uniqueness, enable fast lookups
2. **Unique Constraints** – Prevent duplicates (hash, tag_name, doc_id+tag_id)
3. **Foreign Keys** – Enforce referential integrity (documents → batches)
4. **NOT NULL** – Require critical fields (filename, import_time, hash)
5. **Check Constraints** – Validate ranges (file_size > 0, confidence ∈ [0,1])
6. **Composite Constraints** – Complex rules (one classification per doc per model)

---

## Data Type Compatibility

| Field | PostgreSQL Type | Range | Why This Type |
|-------|-----------------|-------|---------------|
| Hash | VARCHAR(64) | 64-char hex | SHA-256 always 64 chars; VARCHAR allows UNIQUE index |
| Confidence | DECIMAL(3,2) | 0.00-1.00 | Precise decimal; no floating-point rounding errors |
| File Size | BIGINT | 1-9B | ~1 byte to 1GB practical; BIGINT handles up to ~9GB |
| Timestamp | TIMESTAMPTZ | Any valid | Timezone-aware; correct for multi-region |
| IDs | UUID | N/A | 128-bit; distributed generation; no guessing |

---

## Example Data Integrity Scenarios

### Scenario 1: Import with Duplicate Detection
```
1. documents INSERT: filename=invoice.pdf, sha256_hash=abc123...
2. document_hashes INSERT: hash=abc123..., is_duplicate=FALSE
3. audit_log INSERT: entity_type=document, action=import

Later...

4. documents INSERT: filename=invoice_copy.pdf, sha256_hash=abc123... (FAILS)
   → Constraint violation: UNIQUE(sha256_hash) triggers
   → Duplicate detection occurs at database level (zero false negatives)
```

### Scenario 2: Tag Assignment with Cascade Delete
```
1. document_tags INSERT: doc_id=660e8400..., tag_id=1
2. audit_log INSERT: entity_type=tag, action=tagged

If document deleted:
3. documents DELETE WHERE id=660e8400...
4. document_tags AUTOMATIC DELETE (ON DELETE CASCADE)
   → No orphaned tags; referential integrity maintained
```

### Scenario 3: Audit Trail Immutability
```
1. audit_log INSERT: action=import (created_at=now())
2. audit_log never updated (IMMUTABLE pattern)
   → Historical record preserved forever
   → Forensic capability: can trace any change to any entity
```

---

**Document Status:** Data dictionary complete and implementation-ready.
